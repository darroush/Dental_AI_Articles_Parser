PMID,Author,Title,Journal,Year,Abstract,DOI
39327675,"['Oguzhan, Aybeniz', 'Peskersoy, Cem', 'Devrimci, Elif Ercan', 'Kemaloglu, Hande', 'Onder, Tolga Kagan']",Implementation of machine learning models as a quantitative evaluation tool for preclinical studies in dental education.,Journal of dental education,2024 Sep 26,"PURPOSE AND OBJECTIVE: Objective, valid, and reliable evaluations are needed in order to develop haptic skills in dental education. The aim of this study is to investigate the validity and reliability of the machine learning method in evaluating the haptic skills of dentistry students. MATERIALS AND METHODS: One-hundred fifty 6th semester dental students have performed Class II amalgam (C2A) and composite resin restorations (C2CR), in which all stages were evaluated with Direct Observation Practical Skills forms. The final phase was graded by three trainers and supervisors separately. Standard photographs of the restorations in the final stage were taken from different angles in a special setup and transferred to the Python program which utilized the Structural Similarity algorithm to calculate both the quantitative (numerical) and qualitative (visual) differences of each restoration. The validity and reliability analyses of inter-examiner evaluation were tested by Cronbach's Alpha and Kappa statistics (p = 0.05). RESULTS: The intra-examiner reliability between Structural Similarity Index (SSIM) and examiners was found highly reliable in both C2A (α = 0.961) and C2CR (α = 0.856). The compatibility of final grades given by SSIM (53.07) and examiners (56.85) was statistically insignificant (p > 0.05). A significant difference was found between the examiners and SSIM when grading the occlusal surfaces in C2A and on the palatal surfaces of C2CR (p < 0.05). The concordance of observer assessments was found almost perfect in C2A (κ = 0.806), and acceptable in C2CR (κ = 0.769). CONCLUSION: Although deep machine learning is a promising tool in the evaluation of haptic skills, further improvement and alignments are required for fully objective and reliable validation in all cases of dental training in restorative dentistry.",https://doi.org/10.1002/jdd.13722
39326724,"['Çakmak, Gülce', 'Cho, Jun-Ho', 'Choi, Jinhyeok', 'Yoon, Hyung-In', 'Yilmaz, Burak', 'Schimmel, Martin']","Can deep learning-designed anterior tooth-borne crown fulfill morphologic, aesthetic, and functional criteria in clinical practice?",Journal of dentistry,2024 Sep 24,"OBJECTIVES: This study aimed to compare the design outcomes of anterior crowns generated using deep learning (DL)-based software with those fabricated by a technician using conventional dental computer-assisted design (CAD) software without DL support, with a focus on the evaluation of crown morphology, function, and aesthetics. METHODS: Twenty-five in vivo datasets comprising maxillary and mandibular arch scans of prepared maxillary central incisors were utilized to design anterior crowns by using three methods: 1) a DL-based method resulting in as-generated outcome (DB), 2) a DL-based method further optimized by a technician (DM), and 3) a conventional CAD-based method (NC, control). Evaluations were conducted for crown morphology (total discrepancy volume (TDV), root mean square (RMS), positive average (PA) and negative average (NA) deviations), functional aspects (incisal path: deviations, length, and mean inclination), and aesthetics (crown width, height, width-to-height ratio, angular radius of mesioincisal line angle, proximal contact length, and tooth axis angle). RESULTS: Significant differences in TDV ratio were noted between the DB-NC (32.3 ±8.5%) and DM-NC (26.5 ±5.4%) pairs (P = 0.006). No significant differences were observed in TDV between the DB-NC (65.3 ±24.4 mm(3)) and DM-NC (54.3 ±21.0 mm(3)) pairs (P = 0.095). For the entire palatal surface, significant differences in RMS and PA values were observed between the DB-NC and DM-NC pairs (P < 0.037). Significant differences in RMS values for the incisal half (P = 0.021) and in PA values for the cervical half (P = 0.047) of the palatal surface were also noted between these pairs. Significant differences in the deviation of the incisal path were observed between the DB-NC (290.4 ±212.4 μm) and DM-NC (132.0 ±122.3 μm) pairs (P<0.001). However, no significant differences were found among the groups (DB, DM, and NC) in terms of the length and mean inclination of incisal paths or in aesthetic outcomes. CONCLUSIONS: A DL-based method can result in promising outcomes with clinically acceptable morphology and aesthetics for anterior crowns. Minor deviations in incisal path of the crowns may lead to anterior guidance discrepancies, which can be corrected by the dental technician at the design stage. CLINICAL SIGNIFICANCE: With the potential of DL-based design methods in dental applications, integrating AI technology into dental CAD workflow can enhance the clinical efficiency and consistency of anterior crown design, although human intervention may be required to refine functional aspect.",https://doi.org/10.1016/j.jdent.2024.105368
39324972,"['Guler, Ridvan', 'Yalcin, Emine', 'Gulsun, Belgin']",Evaluation of Attitudes and Perceptions in Students About the Use of Artificial Intelligence in Craniomaxillofacial Surgery.,The Journal of craniofacial surgery,2024 Sep 26,"Developments in technology have created great changes in the field of medicine and dentistry. Artificial intelligence technology is one of the most important innovations that caused this change. This study aimed to evaluate the opinions of dentistry students regarding the use of artificial intelligence in dentistry and craniomaxillofacial surgery. Two hundred ninety-six dentistry students between the ages of 19 and 30 participated in the study. Participants submitted the survey by e-mail examining the student's opinions and attitudes regarding the use of artificial intelligence in dentistry and craniomaxillofacial surgery. Respondents' anonymity was ensured. 47.30% (n: 140) of the students participating in the study are fourth-year students, and 52.70% (n: 156) are fifth-year students. While 48.98% (n: 145) of the participants have knowledge about the uses of artificial intelligence in daily life, 28.37% (n: 84) of the students have knowledge about robotic surgery. While ~74% of the participants think that artificial intelligence will improve the field of dentistry and craniomaxillofacial surgery, it has been observed that they are not worried about these applications replacing dentists in the future. It was determined that there was no statistically significant difference between fourth-year and fifth-year students in their knowledge levels about the areas of use of artificial intelligence (P=0.548). Students' opinions show that 74% agree that artificial intelligence will lead to major advances in the field of dentistry and craniomaxillofacial surgery. This shows the relationship between dentists and artificial intelligence points to a bright future.",https://doi.org/10.1097/SCS.0000000000010687
39316174,"['Tomo, Saygo', 'Lechien, Jérôme R', 'Bueno, Hugo Sobrinho', 'Cantieri-Debortoli, Daniela Filié', 'Simonato, Luciana Estevam']",Accuracy and consistency of ChatGPT-3.5 and - 4 in providing differential diagnoses in oral and maxillofacial diseases: a comparative diagnostic performance analysis.,Clinical oral investigations,2024 Sep 24,"OBJECTIVE: To investigate the performance of ChatGPT in the differential diagnosis of oral and maxillofacial diseases. METHODS: Thirty-seven oral and maxillofacial lesions findings were presented to ChatGPT-3.5 and - 4, 18 dental surgeons trained in oral medicine/pathology (OMP), 23 general dental surgeons (DDS), and 16 dental students (DS) for differential diagnosis. Additionally, a group of 15 general dentists was asked to describe 11 cases to ChatGPT versions. The ChatGPT-3.5, -4, and human primary and alternative diagnoses were rated by 2 independent investigators with a 4 Likert-Scale. The consistency of ChatGPT-3.5 and - 4 was evaluated with regenerated inputs. RESULTS: Moderate consistency of outputs was observed for ChatGPT-3.5 and - 4 to provide primary (κ = 0.532 and κ = 0.533 respectively) and alternative (κ = 0.337 and κ = 0.367 respectively) hypotheses. The mean of correct diagnoses was 64.86% for ChatGPT-3.5, 80.18% for ChatGPT-4, 86.64% for OMP, 24.32% for DDS, and 16.67% for DS. The mean correct primary hypothesis rates were 45.95% for ChatGPT-3.5, 61.80% for ChatGPT-4, 82.28% for OMP, 22.72% for DDS, and 15.77% for DS. The mean correct diagnosis rate for ChatGPT-3.5 with standard descriptions was 64.86%, compared to 45.95% with participants' descriptions. For ChatGPT-4, the mean was 80.18% with standard descriptions and 61.80% with participant descriptions. CONCLUSION: ChatGPT-4 demonstrates an accuracy comparable to specialists to provide differential diagnosis for oral and maxillofacial diseases. Consistency of ChatGPT to provide diagnostic hypotheses for oral diseases cases is moderate, representing a weakness for clinical application. The quality of case documentation and descriptions impacts significantly on the performance of ChatGPT. CLINICAL RELEVANCE: General dentists, dental students and specialists in oral medicine and pathology may benefit from ChatGPT-4 as an auxiliary method to define differential diagnosis for oral and maxillofacial lesions, but its accuracy is dependent on precise case descriptions.",https://doi.org/10.1007/s00784-024-05939-1
39311453,"['Ducret, M', 'Wahal, E', 'Gruson, D', 'Amrani, S', 'Richert, R', 'Mouncif-Moungache, M', 'Schwendicke, F']",Trustworthy Artificial Intelligence in Dentistry: Learnings from the EU AI Act.,Journal of dental research,2024 Sep 23,"Artificial intelligence systems (AISs) gain relevance in dentistry, encompassing diagnostics, treatment planning, patient management, and therapy. However, questions about the generalizability, fairness, and transparency of these systems remain. Regulatory and governance bodies worldwide are aiming to address these questions using various frameworks. On March 13, 2024, members of the European Parliament approved the Artificial Intelligence Act (AIA), which emphasizes trustworthiness and human-centeredness as relevant aspects to regulate AISs beyond safety and efficacy. This review presents the AIA and similar regulatory and governance efforts in other jurisdictions and lays out that regulations such as the AIA are part of a complex ecosystem of interdependent and interwoven legal requirements and standards. Current efforts to regulate dental AISs require active input from the dental community, with participation of dental research, education, providers, and patients being relevant to shape the future of dental AISs.",https://doi.org/10.1177/00220345241271160
39311330,"['Turosz, Natalia', 'Chęcińska, Kamila', 'Chęciński, Maciej', 'Lubecka, Karolina', 'Bliźniak, Filip', 'Sikora, Maciej']",Artificial Intelligence (AI) Assessment of Pediatric Dental Panoramic Radiographs (DPRs): A Clinical Study.,Pediatric reports,2024 Sep 11,"This clinical study aimed to evaluate the sensitivity, specificity, accuracy, and precision of artificial intelligence (AI) in assessing permanent teeth in pediatric patients. Over one thousand consecutive DPRs taken in Kielce, Poland, with the Carestream CS9600 device were screened. In the study material, 35 dental panoramic radiographs (DPRs) of patients of developmental age were identified and included. They were automatically evaluated with an AI algorithm. The DPRs were then analyzed by researchers. The status of the following dichotomous variables was assessed: (1) decay, (2) missing tooth, (3) filled tooth, (4) root canal filling, and (5) endodontic lesion. The results showed high specificity and accuracy (all above 85%) in detecting caries, dental fillings, and missing teeth but low precision. This study provided a detailed assessment of AI performance in a previously neglected age group. In conclusion, the overall accuracy of AI algorithms for evaluating permanent dentition in dental panoramic radiographs is lower for pediatric patients than adults or the entire population. Hence, identifying primary teeth should be implemented in AI-driven software, at least so as to ignore them when assessing mixed dentition (ClinicalTrials.gov registration number: NCT06258798).",https://doi.org/10.3390/pediatric16030067
39311162,"['Gaudin, Robert', 'Otto, Wolfram', 'Ghanad, Iman', 'Kewenig, Stephan', 'Rendenbach, Carsten', 'Alevizakos, Vasilios', 'Grün, Pascal', 'Kofler, Florian', 'Heiland, Max', 'von See, Constantin']",Enhanced Osteoporosis Detection Using Artificial Intelligence: A Deep Learning Approach to Panoramic Radiographs with an Emphasis on the Mental Foramen.,"Medical sciences (Basel, Switzerland)",2024 Sep 20,"Osteoporosis, a skeletal disorder, is expected to affect 60% of women aged over 50 years. Dual-energy X-ray absorptiometry (DXA) scans, the current gold standard, are typically used post-fracture, highlighting the need for early detection tools. Panoramic radiographs (PRs), common in annual dental evaluations, have been explored for osteoporosis detection using deep learning, but methodological flaws have cast doubt on otherwise optimistic results. This study aims to develop a robust artificial intelligence (AI) application for accurate osteoporosis identification in PRs, contributing to early and reliable diagnostics. A total of 250 PRs from three groups (A: osteoporosis group, B: non-osteoporosis group matching A in age and gender, C: non-osteoporosis group differing from A in age and gender) were cropped to the mental foramen region. A pretrained convolutional neural network (CNN) classifier was used for training, testing, and validation with a random split of the dataset into subsets (A vs. B, A vs. C). Detection accuracy and area under the curve (AUC) were calculated. The method achieved an F1 score of 0.74 and an AUC of 0.8401 (A vs. B). For young patients (A vs. C), it performed with 98% accuracy and an AUC of 0.9812. This study presents a proof-of-concept algorithm, demonstrating the potential of deep learning to identify osteoporosis in dental radiographs. It also highlights the importance of methodological rigor, as not all optimistic results are credible.",https://doi.org/10.3390/medsci12030049
39306752,"['Santos, José Wittor de Macêdo', 'Mueller, Andreas Albert', 'Benitez, Benito K', 'Lill, Yoriko', 'Nalabothu, Prasad', 'Muniz, Francisco Wilker Mustafa Gomes']",Smartphone-based scans of palate models of newborns with cleft lip and palate: Outlooks for three-dimensional image capturing and machine learning plate tool.,Orthodontics & craniofacial research,2024 Sep 22,"OBJECTIVES: To evaluate the performance of smartphone scanning applications (apps) in acquiring 3D meshes of cleft palate models. Secondarily, to validate a machine learning (ML) tool for computing automated presurgical plate (PSP). MATERIALS AND METHODS: We conducted a comparative analysis of two apps on 15 cleft palate models: five unilateral cleft lip and palate (UCLP), five bilateral cleft lip and palate (BCLP) and five isolated cleft palate (ICP). The scans were performed with and without a mirror to simulate intraoral acquisition. The 3D reconstructions were compared to control reconstructions acquired using a professional intraoral scanner using open-source software. RESULTS: Thirty 3D scans were acquired by each app, totalling 60 scans. The main findings were in the UCLP sample, where the KIRI scans without a mirror (0.22 ± 0.03 mm) had a good performance with a deviation from the ground truth comparable to the control group (0.14 ± 0.13 mm) (p = .653). Scaniverse scans with a mirror showed the lowest accuracy of all the samples. The ML tool was able to predict the landmarks and automatically generate the plates, except in ICP models. KIRI scans' plates showed better performance with (0.22 ± 0.06 mm) and without mirror (0.18 ± 0.05 mm), being comparable with controls (0.16 ± 0.08 mm) (p = .954 and p = .439, respectively). CONCLUSIONS: KIRI Engine performed better in scanning UCLP models without a mirror. The ML tool showed a high capability for morphology recognition and automated PSP generation.",https://doi.org/10.1111/ocr.12859
39302479,"['Chen, Xu', 'Shen, Yiran', 'Jeong, Jin-Sun', 'Perinpanayagam, Hiran', 'Kum, Kee-Yeon', 'Gu, Yu']",DeepPlaq: Dental plaque indexing based on deep neural networks.,Clinical oral investigations,2024 Sep 20,"OBJECTIVES: The selection of treatment for dental plaque is closely related to the condition of the plaque on different teeth. This study validated the ability of CNN models in assessing the dental plaque indices. MATERIALS AND METHODS: In 70 (20 male and 50 female) healthy adults (18 to 55 years old), frontal and lateral view intraoral images (210) of plaque disclosing agent stained permanent and deciduous dentitions were obtained. A three-stage method was employed, where the You Look Only Once version 8 (YOLOv8) model was first used to detect the target teeth, followed by the prompt-based Segment Anything Model (SAM) segmentation algorithm to segment teeth. A new single-tooth dataset consisting of 1400 photographs was obtained after applying a two-stage method. Finally, a multi-class classification model DeepPlaq was trained and evaluated on the accuracy of dental plaque indexing based on the Quigley-Hein Index (QHI) scoring system. Classification performance was measured using accuracy, recall, precision, and F1-score. RESULTS: The teeth detector exhibited an accuracy (mean average precision, mAP) of approximately 0.941 ± 0.005 in identifying teeth with plaque disclosing agents. The maximum accuracy attained in the plaque indexing through DeepPlaq was 0.84 (probability that DeepPlaq scored identical to experts), and the smallest average scoring error was less than 0.25 on a 0 to 5 scale for scoring. CONCLUSIONS: A three-stage approach demonstrated excellent performance in detecting and segmenting target teeth, and DeepPlaq model also showed strong performance in assessing dental plaque indices. CLINICAL RELEVANCE: Application of artificial intelligence to the evaluation of dental plaque distribution could enhance diagnostic accuracy and treatment efficiency and accuracy.",https://doi.org/10.1007/s00784-024-05921-x
39294554,"['Bizjak, Žiga', 'Robič, Tina']",DentAge: Deep learning for automated age prediction using panoramic dental X-ray images.,Journal of forensic sciences,2024 Sep 18,"Age estimation plays a crucial role in various fields, including forensic science and anthropology. This study aims to develop and validate DentAge, a deep-learning model for automated age prediction using panoramic dental X-ray images. DentAge was trained on a dataset comprising 21,007 panoramic dental X-ray images sourced from a private dental center in Slovenia. The dataset included subjects aged 4 to 97 years with various dental conditions. Transfer learning was employed, initializing the model with ImageNet weights and fine-tuning on the dental image dataset. The model was trained using stochastic gradient descent with momentum, and mean absolute error (MAE) served as the objective function. Across the test dataset, DentAge achieved an MAE of 3.12 years, demonstrating its efficacy in age prediction. Notably, the model performed well across different age groups, with MAEs ranging from 1.94 (age group [10-20]) to 13.40 years (age group [90-100]). Visual evaluation revealed factors contributing to prediction errors, including prosthetic restorations, tooth loss, and bone resorption. DentAge represents a significant advancement in automated age prediction within dentistry. The model's robust performance across diverse age groups and dental conditions underscores its potential utility in real-world scenarios. Our model will be accessible to the public for further adjustments and validation, ensuring DentAge's effectiveness and trustworthiness in practical scenarios.",https://doi.org/10.1111/1556-4029.15629
39285427,"['Zhang, Jing-Wen', 'Fan, Jie', 'Zhao, Fang-Bing', ""Ma, Bing'er"", 'Shen, Xiao-Qing', 'Geng, Yuan-Ming']",Diagnostic accuracy of artificial intelligence-assisted caries detection: a clinical evaluation.,BMC oral health,2024 Sep 16,"OBJECTIVE: This clinical study aimed to evaluate the practical value of integrating an AI diagnostic model into clinical practice for caries detection using intraoral images. METHODS: In this prospective study, 4,361 teeth from 191 consecutive patients visiting an endodontics clinic were examined using an intraoral camera. The AI model, combining MobileNet-v3 and U-net architectures, was used for caries detection. The diagnostic performance of the AI model was assessed using sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and accuracy, with the clinical diagnosis by endodontic specialists as the reference standard. RESULTS: The overall accuracy of the AI-assisted caries detection was 93.40%. The sensitivity and specificity were 81.31% (95% CI 78.22%-84.06%) and 95.65% (95% CI 94.94%-96.26%), respectively. The NPV and PPV were 96.49% (95% CI 95.84%-97.04%) and 77.68% (95% CI 74.49%-80.58%), respectively. The diagnostic accuracy varied depending on tooth position and caries type, with the highest accuracy in anterior teeth (96.04%) and the lowest sensitivity for interproximal caries in anterior teeth and buccal caries in premolars (approximately 10%). CONCLUSION: The AI-assisted caries detection tool demonstrated potential for clinical application, with high overall accuracy and specificity. However, the sensitivity varied considerably depending on tooth position and caries type, suggesting the need for further improvement. Integration of multimodal data and development of more advanced AI models may enhance the performance of AI-assisted caries detection in clinical practice.",https://doi.org/10.1186/s12903-024-04847-w
39281043,"['Ma, Tian', 'Dang, Zhenrui', 'Yang, Yizhou', 'Yang, Jiayi', 'Li, Jiahui']",Dental panoramic X-ray image segmentation for multi-feature coordinate position learning.,Digital health,2024 Jan-Dec,"OBJECTIVE: To achieve an accurate assessment of orthodontic and restorative treatments, tooth segmentation of dental panoramic X-ray images is a critical preliminary step, however, dental panoramic X-ray images suffer from poorly defined interdental boundaries and low root-to-alveolar bone contrast, which pose significant challenges to tooth segmentation. In this article, we propose a multi-feature coordinate position learning-based tooth image segmentation method for tooth segmentation. METHODS: For better analysis, the input image is randomly flipped horizontally and vertically to enhance the data. Our method extracts multi-scale tooth features from the designed residual omni-dimensional dynamic convolution and the designed two-stream coordinate attention module can further complement the tooth boundary features, and finally the two features are fused to enhance the local details of the features and global contextual information, which achieves the enrichment and optimization of the feature information. RESULTS: The publicly available adult dental datasets Archive and Dataset and Code were used in the study. The experimental results were 87.96% and 92.04% for IoU, 97.79% and 97.32% for ACC, and 86.42% and 95.64% for Dice. CONCLUSION: The experimental results show that the proposed network can be used to assist doctors in quickly viewing tooth positions, and we also validate the effectiveness of the proposed two modules in fusing features.",https://doi.org/10.1177/20552076241277154
39275850,"['Dziedzic, Arkadiusz', 'Issa, Julien', 'Chaurasia, Akhilanand', 'Tanasiewicz, Marta']",Artificial intelligence and health-related data: The patient's best interest and data ownership dilemma.,"Proceedings of the Institution of Mechanical Engineers. Part H, Journal of engineering in medicine",2024 Sep 14,"The rapid advancement of artificial intelligence (AI) in healthcare has the potential to revolutionize the global healthcare sector and medicine in general. However, integrating AI technologies in healthcare requires access to large amounts of personal health-related data (HRD), which raises concerns regarding confidential personal information considering unregulated and not transparent data ownership. Setting up the patient's welfare as an unquestionable principle, this commentary explores the various ethical aspects of using HRD in AI applications, focusing on informed consent, data ownership, data sharing, financial considerations, accountability, and ethical standards. Three models of potential collaboration between AI-specializing firms and healthcare providers are evaluated: the commercial model, the equitable profit-sharing model, and the public-funded non-profit model. Each model has its advantages and challenges, necessitating a careful balance between ethical considerations, financial implications, and technological advancements. Policymakers and healthcare regulators are urged to establish transparent legislation to safeguard patient privacy, ensure informed consent, and promote the responsible use of HRD in AI applications. This commentary emphasizes the importance of addressing ethical issues to protect basic patient rights, foster responsible collaborations, and ensure the ethical use of health-related data in AI-based healthcare applications. While the coexistence of regulated AI and healthcare professionals is inevitable for validating the cost-effectiveness of AI use in healthcare economics, the transparency of HRD sources is deemed of utmost importance in the best interest of the patient.",https://doi.org/10.1177/09544119241279630
39274428,"['Schwarzmaier, Julia', 'Frenkel, Elisabeth', 'Neumayr, Julia', 'Ammar, Nour', 'Kessler, Andreas', 'Schwendicke, Falk', 'Kühnisch, Jan', 'Dujic, Helena']",Validation of an Artificial Intelligence-Based Model for Early Childhood Caries Detection in Dental Photographs.,Journal of clinical medicine,2024 Sep 3,"Background/Objectives: Early childhood caries (ECC) is a widespread and severe oral health problem that potentially affects the general health of children. Visual-tactile examination remains the diagnostic method of choice to diagnose ECC, although visual examination could be automated by artificial intelligence (AI) tools in the future. The aim of this study was the external validation of a recently published and freely accessible AI-based model for detecting ECC and classifying carious lesions in dental photographs. Methods: A total of 143 anonymised photographs of anterior deciduous teeth (ECC = 107, controls = 36) were visually evaluated by the dental study group (reference test) and analysed using the AI-based model (test method). Diagnostic performance was determined statistically. Results: ECC detection accuracy was 97.2%. Diagnostic performance varied between carious lesion classes (noncavitated lesions, greyish translucency/microcavity, cavitation, destructed tooth), with accuracies ranging from 88.9% to 98.1%, sensitivities ranging from 68.8% to 98.5% and specificities ranging from 86.1% to 99.4%. The area under the curve ranged from 0.834 to 0.964. Conclusions: The performance of the AI-based model is similar to that reported for the internal dataset used by developers. Further studies with independent image samples are required to comprehensively gauge the performance of the model.",https://doi.org/10.3390/jcm13175215
39272733,"['Hao, Jing', 'Wong, Lun M', 'Shan, Zhiyi', 'Ai, Qi Yong H', 'Shi, Xieqi', 'Tsoi, James Kit Hon', 'Hung, Kuo Feng']",A Semi-Supervised Transformer-Based Deep Learning Framework for Automated Tooth Segmentation and Identification on Panoramic Radiographs.,"Diagnostics (Basel, Switzerland)",2024 Sep 3,"Automated tooth segmentation and identification on dental radiographs are crucial steps in establishing digital dental workflows. While deep learning networks have been developed for these tasks, their performance has been inferior in partially edentulous individuals. This study proposes a novel semi-supervised Transformer-based framework (SemiTNet), specifically designed to improve tooth segmentation and identification performance on panoramic radiographs, particularly in partially edentulous cases, and establish an open-source dataset to serve as a unified benchmark. A total of 16,317 panoramic radiographs (1589 labeled and 14,728 unlabeled images) were collected from various datasets to create a large-scale dataset (TSI15k). The labeled images were divided into training and test sets at a 7:1 ratio, while the unlabeled images were used for semi-supervised learning. The SemiTNet was developed using a semi-supervised learning method with a label-guided teacher-student knowledge distillation strategy, incorporating a Transformer-based architecture. The performance of SemiTNet was evaluated on the test set using the intersection over union (IoU), Dice coefficient, precision, recall, and F1 score, and compared with five state-of-the-art networks. Paired t-tests were performed to compare the evaluation metrics between SemiTNet and the other networks. SemiTNet outperformed other networks, achieving the highest accuracy for tooth segmentation and identification, while requiring minimal model size. SemiTNet's performance was near-perfect for fully dentate individuals (all metrics over 99.69%) and excellent for partially edentulous individuals (all metrics over 93%). In edentulous cases, SemiTNet obtained statistically significantly higher tooth identification performance than all other networks. The proposed SemiTNet outperformed previous high-complexity, state-of-the-art networks, particularly in partially edentulous cases. The established open-source TSI15k dataset could serve as a unified benchmark for future studies.",https://doi.org/10.3390/diagnostics14171948
39266401,"['Lu, Wei', 'Yu, Xueqian', 'Li, Yueyang', 'Cao, Yi', 'Chen, Yanning', 'Hua, Fang']",Artificial Intelligence-Related Dental Research: Bibliometric and Altmetric Analysis.,International dental journal,2024 Sep 11,"BACKGROUND: Recent years have witnessed an explosive surge in dental research related to artificial intelligence (AI). These applications have optimised dental workflows, demonstrating significant clinical importance. Understanding the current landscape and trends of this topic is crucial for both clinicians and researchers to utilise and advance this technology. However, a comprehensive scientometric study regarding this field had yet to be performed. METHODS: A literature search was conducted in the Web of Science Core Collection database to identify eligible ""research articles"" and ""reviews."" Literature screening and exclusion were performed by 2 investigators. Thereafter, VOSviewer was utilised in co-occurrence analysis and CiteSpace in co-citation analysis. R package Bibliometrix was employed to automatically calculate scientific impacts, determining the core authors and journals. Altmetric data were described narratively and supplemented with Spearman correlation analysis. RESULTS: A total of 1558 research publications were included. During the past 5 years, AI-related dental publications drastically increased in number, from 36 to 581. Diagnostics and Scientific Reports published the most articles, whereas Journal of Dental Research received the highest number of citations per article. China, the US, and South Korea emerged as the most prolific countries, whilst Germany received the highest number of citations per article (23.29). Charité Universitätsmedizin Berlin was the institution with the highest number of publications and citations per article (29.16). Altmetric Attention Score was correlated with News Mentions (P < .001), and significant associations were observed amongst Dimension Citations, Mendeley Readers, and Web of Science Citations (P < .001). CONCLUSIONS: The publication numbers regarding AI-related dental research have been rising rapidly and may continue their upwards trend. China, the US, South Korea, and Germany had promoted the progress of AI-related dental research. Disease diagnosis, orthodontic applications, and morphology segmentation were current hotspots. Attention mechanism, explainable AI, multimodal data fusion, and AI-generated text assistants necessitate future research and exploration.",https://doi.org/10.1016/j.identj.2024.08.004
39254786,"['Veseli, E']",Artificial intelligence progress in the diagnosis of oral mucosal lesions: implications for pediatric dental health.,European archives of paediatric dentistry : official journal of the European Academy of Paediatric Dentistry,2024 Sep 10,,https://doi.org/10.1007/s40368-024-00944-0
39245622,"['Dashti, Mahmood', 'Ghasemi, Shohreh', 'Khurshid, Zohaib']",Integrating Artificial Intelligence in Dental Education: An Urgent Call for Dedicated Postgraduate Programs.,International dental journal,2024 Sep 7,,https://doi.org/10.1016/j.identj.2024.08.008
39242442,"['Li, Zheng', 'Li, Zhongqiang', 'Zhang, Ya', 'Wang, Huaizhi', 'Li, Xin', 'Zhang, Jian', 'Zaid, Waleed', 'Yao, Shaomian', 'Xu, Jian']",Human Tooth Crack Image Analysis with Multiple Deep Learning Approaches.,Annals of biomedical engineering,2024 Sep 6,"Tooth cracks, one of the most common dental diseases, can result in the tooth falling apart without prompt treatment; dentists also have difficulty locating cracks, even with X-ray imaging. Indocyanine green (ICG) assisted near-infrared fluorescence (NIRF) dental imaging technique can solve this problem due to the deep penetration of NIR light and the excellent fluorescence characteristics of ICG. This study extracted 593 human cracked tooth images and 601 non-cracked tooth images from NIR imaging videos. Multiple imaging analysis methods such as classification, object detection, and super-resolution were applied to the dataset for cracked image analysis. Our results showed that machine learning methods could help analyze tooth crack efficiently: the tooth images with cracks and without cracks could be well classified with the pre-trained residual network and squeezenet1_1 models, with a classification accuracy of 88.2% and 94.25%, respectively; the single shot multi-box detector (SSD) was able to recognize cracks, even if the input image was at a different size from the original cracked image; the super-resolution (SR) model, SR-generative adversarial network demonstrated enhanced resolution of crack images using high-resolution concrete crack images as the training dataset. Overall, deep learning model-assisted human crack analysis improves crack identification; the combination of our NIR dental imaging system and deep learning models has the potential to assist dentists in crack diagnosis.",https://doi.org/10.1007/s10439-024-03615-9
39242274,"['Farook, Taseef Hasan', 'Ramees, Lameesa', 'Dudley, James']","Relationship between anterior occlusion, arch dimension, and mandibular movement during speech articulation: A three-dimensional analysis.",The Journal of prosthetic dentistry,2024 Sep 5,"STATEMENT OF PROBLEM: Studies correlating occlusal morphology from 3-dimensional intraoral scans with both soft and hard tissue dynamic landmark tracking within the same participant population are lacking. PURPOSE: The purpose of this clinical study was to use 3-dimensional intraoral scanning, computer-aided design, electrognathography, and artificial intelligence to investigate the relationships between anterior occlusion and arch parameters with hard and soft tissue displacements during speech production. MATERIAL AND METHODS: An artificial intelligence (AI) driven software program and electrognathography was used to record the phonetic activities in 62 participants for soft tissue (ST) and hard tissue (HT) displacement. Soft tissue displacement was quantified by the mean difference between subnasale and soft tissue pogonion peaks during phonetic expressions, and hard tissue displacement was directly measured with an electrognathograph. Intercanine and intermolar distances, arch perimeters, and horizontal and vertical overlap were measured from the intraoral scan data. RESULTS: ST and HT displacements were successfully estimated for fricative (ST=7.16 ±4.51 mm, HT=11.86 ±4.02 mm), sibilant (ST=5.11 ±3.49 mm, HT=8.24 ±3.31 mm), linguodental (ST=5.72 ±4.46 mm, HT=10.01 ±3.16 mm), and bilabial (ST=5.56 ±4.64 mm, HT=11.69 ±4.28 mm) phonetics. Vertical overlap correlated positively with hard tissue movement during all speech expressions except bilabial phonetics (ρ=.30 to.41, P<.05). Maxillary and mandibular arch perimeters showed negative correlations with soft tissue displacement during linguodental and bilabial speech (ρ=-.25 to -.41, P<.05) but were significantly correlated with hard tissue movement during all speech assessments (ρ=-.28 to -.44, P<.05). Maxillary intermolar distances negatively correlated with hard tissue phonetic expressions (ρ=-.24 to -.30, P<.05). Participant age positively correlated with soft tissue displacement during all speech patterns (ρ=.28 to.33, P<.05) and with weight increase (ρ=.27, P=.033), and hard tissue displacement (ρ=.25, P=.048) during maximum mouth opening significantly correlated with linguodental phonetics. CONCLUSIONS: Within the study population, vertical overlap, maxillary intermolar distance, and dental arch perimeters correlated significantly with mandibular displacement during phonetic expression.",https://doi.org/10.1016/j.prosdent.2024.08.001
39241044,"['Kang, Sohee', 'Shon, Byungeun', 'Park, Eun Young', 'Jeong, Sungmoon', 'Kim, Eun-Kyong']",Diagnostic accuracy of dental caries detection using ensemble techniques in deep learning with intraoral camera images.,PloS one,2024,"Camera image-based deep learning (DL) techniques have achieved promising results in dental caries screening. To apply the intraoral camera image-based DL technique for dental caries detection and assess its diagnostic performance, we employed the ensemble technique in the image classification task. 2,682 intraoral camera images were used as the dataset for image classification according to dental caries presence and caries-lesion localization using DL models such as ResNet-50, Inception-v3, Inception-ResNet-v2, and Faster R-convolutional neural network according to diagnostic study design. 534 participants whose mean age [SD] was 47.67 [±13.94] years were enrolled. The dataset was divided into training (56.0%), validation (14.0%), and test subset (30.0%) annotated by one experienced dentist as a reference standard about dental caries detection and lesion location. The confusion matrix, area under the receiver operating characteristic curve (AUROC), and average precision (AP) were evaluated for performance analysis. In the end-to-end dental caries image classification, the ensemble DL models had consistently improved performance, in which as the best results, the ensemble model of Inception-ResNet-v2 achieved 0.94 of AUROC and 0.97 of AP. On the other hand, the explainable model achieved 0.91 of AUROC and 0.96 of AP after the ensemble application. For dental caries classification using intraoral camera images, the application of ensemble techniques exhibited consistently improved performance regardless of the DL models. Furthermore, the trial to create an explainable DL model based on carious lesion detection yielded favorable results.",https://doi.org/10.1371/journal.pone.0310004
39232939,"['Talib, Manar Abu', 'Moufti, Mohammad Adel', 'Nasir, Qassim', 'Kabbani, Yousuf', 'Aljaghber, Dana', 'Afadar, Yaman']",Transfer Learning-Based Classifier to Automate the Extraction of False X-Ray Images From Hospital's Database.,International dental journal,2024 Sep 3,"BACKGROUND: During preclinical training, dental students take radiographs of acrylic (plastic) blocks containing extracted patient teeth. With the digitisation of medical records, a central archiving system was created to store and retrieve all x-ray images, regardless of whether they were images of teeth on acrylic blocks, or those from patients. In the early stage of the digitisation process, and due to the immaturity of the data management system, numerous images were mixed up and stored in random locations within a unified archiving system, including patient record files. Filtering out and expunging the undesired training images is imperative as manual searching for such images is problematic. Hence the aim of this stidy was to differentiate intraoral images from artificial images on acrylic blocks. METHODS: An artificial intelligence (AI) solution to automatically differentiate between intraoral radiographs taken of patients and those taken of acrylic blocks was utilised in this study. The concept of transfer learning was applied to a dataset provided by a Dental Hospital. RESULTS: An accuracy score, F1 score, and a recall score of 98.8%, 99.2%, and 100%, respectively, were achieved using a VGG16 pre-trained model. These results were more sensitive compared to those obtained initally using a baseline model with 96.5%, 97.5%, and 98.9% accuracy score, F1 score, and a recall score respectively. CONCLUSIONS: The proposed system using transfer learning was able to accurately identify ""fake"" radiographs images and distinguish them from the real intraoral images.",https://doi.org/10.1016/j.identj.2024.08.002
39230022,"['Cho, Sung Joo', 'Moon, Jun-Ho', 'Ko, Dong-Yub', 'Lee, Ju-Myung', 'Park, Ji-Ae', 'Donatelli, Richard E', 'Lee, Shin-Jae']",Orthodontic treatment outcome predictive performance differences between artificial intelligence and conventional methods.,The Angle orthodontist,2024 Sep 1,"OBJECTIVES: To evaluate an artificial intelligence (AI) model in predicting soft tissue and alveolar bone changes following orthodontic treatment and compare the predictive performance of the AI model with conventional prediction models. MATERIALS AND METHODS: A total of 1774 lateral cephalograms of 887 adult patients who had undergone orthodontic treatment were collected. Patients who had orthognathic surgery were excluded. On each cephalogram, 78 landmarks were detected using PIPNet-based AI. Prediction models consisted of 132 predictor variables and 88 outcome variables. Predictor variables were demographics (age, sex), clinical (treatment time, premolar extraction), and Cartesian coordinates of the 64 anatomic landmarks. Outcome variables were Cartesian coordinates of the 22 soft tissue and 22 hard tissue landmarks after orthodontic treatment. The AI prediction model was based on the TabNet deep neural network. Two conventional statistical methods, multivariate multiple linear regression (MMLR) and partial least squares regression (PLSR), were each implemented for comparison. Prediction accuracy among the methods was compared. RESULTS: Overall, MMLR demonstrated the most accurate results, while AI was least accurate. AI showed superior predictions in only 5 of the 44 anatomic landmarks, all of which were soft tissue landmarks inferior to menton to the terminal point of the neck. CONCLUSIONS: When predicting changes following orthodontic treatment, AI was not as effective as conventional statistical methods. However, AI had an outstanding advantage in predicting soft tissue landmarks with substantial variability. Overall, results may indicate the need for a hybrid prediction model that combines conventional and AI methods.",https://doi.org/10.2319/111823-767.1
39230019,"['Park, Ji-Ae', 'Moon, Jun-Ho', 'Lee, Ju-Myung', 'Cho, Sung Joo', 'Seo, Byoung-Moo', 'Donatelli, Richard E', 'Lee, Shin-Jae']",Does artificial intelligence predict orthognathic surgical outcomes better than conventional linear regression methods?,The Angle orthodontist,2024 Sep 1,"OBJECTIVES: To evaluate the performance of an artificial intelligence (AI) model in predicting orthognathic surgical outcomes compared to conventional prediction methods. MATERIALS AND METHODS: Preoperative and posttreatment lateral cephalograms from 705 patients who underwent combined surgical-orthodontic treatment were collected. Predictors included 254 input variables, including preoperative skeletal and soft-tissue characteristics, as well as the extent of orthognathic surgical repositioning. Outcomes were 64 Cartesian coordinate variables of 32 soft-tissue landmarks after surgery. Conventional prediction models were built applying two linear regression methods: multivariate multiple linear regression (MLR) and multivariate partial least squares algorithm (PLS). The AI-based prediction model was based on the TabNet deep neural network. The prediction accuracy was compared, and the influencing factors were analyzed. RESULTS: In general, MLR demonstrated the poorest predictive performance. Among 32 soft-tissue landmarks, PLS showed more accurate prediction results in 16 soft-tissue landmarks above the upper lip, whereas AI outperformed in six landmarks located in the lower border of the mandible and neck area. The remaining 10 landmarks presented no significant difference between AI and PLS prediction models. CONCLUSIONS: AI predictions did not always outperform conventional methods. A combination of both methods may be more effective in predicting orthognathic surgical outcomes.",https://doi.org/10.2319/111423-756.1
39227811,"['Quah, Bernadette', 'Zheng, Lei', 'Sng, Timothy Jie Han', 'Yong, Chee Weng', 'Islam, Intekhab']",Reliability of ChatGPT in automated essay scoring for dental undergraduate examinations.,BMC medical education,2024 Sep 3,"BACKGROUND: This study aimed to answer the research question: How reliable is ChatGPT in automated essay scoring (AES) for oral and maxillofacial surgery (OMS) examinations for dental undergraduate students compared to human assessors? METHODS: Sixty-nine undergraduate dental students participated in a closed-book examination comprising two essays at the National University of Singapore. Using pre-created assessment rubrics, three assessors independently performed manual essay scoring, while one separate assessor performed AES using ChatGPT (GPT-4). Data analyses were performed using the intraclass correlation coefficient and Cronbach's α to evaluate the reliability and inter-rater agreement of the test scores among all assessors. The mean scores of manual versus automated scoring were evaluated for similarity and correlations. RESULTS: A strong correlation was observed for Question 1 (r = 0.752-0.848, p < 0.001) and a moderate correlation was observed between AES and all manual scorers for Question 2 (r = 0.527-0.571, p < 0.001). Intraclass correlation coefficients of 0.794-0.858 indicated excellent inter-rater agreement, and Cronbach's α of 0.881-0.932 indicated high reliability. For Question 1, the mean AES scores were similar to those for manual scoring (p > 0.05), and there was a strong correlation between AES and manual scores (r = 0.829, p < 0.001). For Question 2, AES scores were significantly lower than manual scores (p < 0.001), and there was a moderate correlation between AES and manual scores (r = 0.599, p < 0.001). CONCLUSION: This study shows the potential of ChatGPT for essay marking. However, an appropriate rubric design is essential for optimal reliability. With further validation, the ChatGPT has the potential to aid students in self-assessment or large-scale marking automated processes.",https://doi.org/10.1186/s12909-024-05881-6
39227802,"['Kurt, Ayça', 'Günaçar, Dilara Nil', 'Şılbır, Fatma Yanık', 'Yeşil, Zeynep', 'Bayrakdar, İbrahim Şevki', 'Çelik, Özer', 'Bilgir, Elif', 'Orhan, Kaan']",Evaluation of tooth development stages with deep learning-based artificial intelligence algorithm.,BMC oral health,2024 Sep 3,"BACKGROUND: This study aims to evaluate the performance of a deep learning system for the evaluation of tooth development stages on images obtained from panoramic radiographs from child patients. METHODS: The study collected a total of 1500 images obtained from panoramic radiographs from child patients between the ages of 5 and 14 years. YOLOv5, a convolutional neural network (CNN)-based object detection model, was used to automatically detect the calcification states of teeth. Images obtained from panoramic radiographs from child patients were trained and tested in the YOLOv5 algorithm. True-positive (TP), false-positive (FP), and false-negative (FN) ratios were calculated. A confusion matrix was used to evaluate the performance of the model. RESULTS: Among the 146 test group images with 1022 labels, there were 828 TPs, 308 FPs, and 1 FN. The sensitivity, precision, and F1-score values of the detection model of the tooth stage development model were 0.99, 0.72, and 0.84, respectively. CONCLUSIONS: In conclusion, utilizing a deep learning-based approach for the detection of dental development on pediatric panoramic radiographs may facilitate a precise evaluation of the chronological correlation between tooth development stages and age. This can help clinicians make treatment decisions and aid dentists in finding more accurate treatment options.",https://doi.org/10.1186/s12903-024-04786-6
39227487,"['Berends, Bo', 'Vinayahalingam, Shankeeth', 'Baan, Frank', 'Flügge, Tabea', 'Maal, Thomas', 'Bergé, Stefaan', 'de Jong, Guide', 'Xi, Tong']",Automated condylar seating assessment using a deep learning-based three-step approach.,Clinical oral investigations,2024 Sep 4,"OBJECTIVES: In orthognatic surgery, one of the primary determinants for reliable three-dimensional virtual surgery planning (3D VSP) and an accurate transfer of 3D VSP to the patient in the operation room is the condylar seating. Incorrectly seated condyles would primarily affect the accuracy of maxillary-first bimaxillary osteotomies as the maxillary repositioning is dependent on the positioning of the mandible in the cone-beam computed tomography (CBCT) scan. This study aimed to develop and validate a novel tool by utilizing a deep learning algorithm that automatically evaluates the condylar seating based on CBCT images as a proof of concept. MATERIALS AND METHODS: As a reference, 60 CBCT scans (120 condyles) were labeled. The automatic assessment of condylar seating included three main parts: segmentation module, ray-casting, and feed-forward neural network (FFNN). The AI-based algorithm was trained and tested using fivefold cross validation. The method's performance was evaluated by comparing the labeled ground truth with the model predictions on the validation dataset. RESULTS: The model achieved an accuracy of 0.80, positive predictive value of 0.61, negative predictive value of 0.9 and F1-score of 0.71. The sensitivity and specificity of the model was 0.86 and 0.78, respectively. The mean AUC over all folds was 0.87. CONCLUSION: The innovative integration of multi-step segmentation, ray-casting and a FFNN demonstrated to be a viable approach for automating condylar seating assessment and have obtained encouraging results. CLINICAL RELEVANCE: Automated condylar seating assessment using deep learning may improve orthognathic surgery, preventing errors and enhancing patient outcomes in maxillary-first bimaxillary osteotomies.",https://doi.org/10.1007/s00784-024-05895-w
39223562,"['Noeldeke, Beatrice', 'Vassis, Stratos', 'Sefidroodi, Mohammedreza', 'Pauwels, Ruben', 'Stoustrup, Peter']",Comparison of deep learning models to detect crossbites on 2D intraoral photographs.,Head & face medicine,2024 Sep 2,"BACKGROUND: To support dentists with limited experience, this study trained and compared six convolutional neural networks to detect crossbites and classify non-crossbite, frontal, and lateral crossbites using 2D intraoral photographs. METHODS: Based on 676 photographs from 311 orthodontic patients, six convolutional neural network models were trained and compared to classify (1) non-crossbite vs. crossbite and (2) non-crossbite vs. lateral crossbite vs. frontal crossbite. The trained models comprised DenseNet, EfficientNet, MobileNet, ResNet18, ResNet50, and Xception. FINDINGS: Among the models, Xception showed the highest accuracy (98.57%) in the test dataset for classifying non-crossbite vs. crossbite images. When additionally distinguishing between lateral and frontal crossbites, average accuracy decreased with the DenseNet architecture achieving the highest accuracy among the models with 91.43% in the test dataset. CONCLUSIONS: Convolutional neural networks show high potential in processing clinical photographs and detecting crossbites. This study provides initial insights into how deep learning models can be used for orthodontic diagnosis of malocclusions based on intraoral 2D photographs.",https://doi.org/10.1186/s13005-024-00448-8
39223002,"['Watt, Matthew', 'Zhu, Steven', 'Deol, Navkiran', 'Ferraro, Nalton']",Beyond the Hype: Practical Artificial Intelligence Uses for Today's Oral and Maxillofacial Surgeons.,Journal of oral and maxillofacial surgery : official journal of the American Association of Oral and Maxillofacial Surgeons,2024 Sep,,https://doi.org/10.1016/j.joms.2024.05.011
39222211,"['Garcovich, Daniele', 'Lipani, Erica', 'Aiuto, Riccardo', 'Alvarado Lorenzo, Alfonso', 'Adobes Martin, Milagros']",Application of digital workflow and technologies in clinical paediatric dentistry: a scoping review.,European archives of paediatric dentistry : official journal of the European Academy of Paediatric Dentistry,2024 Sep 2,"PURPOSE: The purpose of the present scoping review is to map the literature reporting on the application of digital workflows and digital technologies in the diagnosis, treatment, or management of dental conditions in paediatric patients. Furthermore, the review focuses on identifying possible knowledge gaps in the area and developing specific recommendations for future investigations. METHODS: An electronic search was performed on 3 databases up to July 2023. After the authors independently screened the retrieved articles, they extracted the data and assessed the risk of bias using the JBI (The Joanna Briggs Institute) critical appraisal tools and the Cochrane Risk of Bias 1 tool, depending on the study design assessed. RESULTS: After full-text assessment, 58 studies were identified that met the inclusion and exclusion criteria. The results were divided into two groups according to the study design: 36 were research articles, and 22 were case reports; only the research articles were included in the qualitative synthesis. The most common topic was Scanners/3 d digital model analysis (11 articles), followed by Digital Imaging (8 articles). Digital applications were also a popular topic, and tele-dentistry and artificial intelligence were also present in the included studies. CONCLUSION: Studies investigating the use of digital workflows and digital technologies in the diagnosis, treatment or management of dental conditions in paediatric dentistry are lacking. In general, future investigations should be based on higher quality studies; furthermore, the lack of studies on the clinical validation of digitally fabricated orthodontic devices and restorations in paediatric patients provides insights for future research.",https://doi.org/10.1007/s40368-024-00936-0
39219015,"['Delgado-Ruiz, Rafael', 'Kim, Amy S', 'Zhang, Hai', 'Sullivan, Diane', 'Awan, Kamran H', 'Stathopoulou, Panagiota G']","Generative Artificial Intelligence (Gen AI) in dental education: Opportunities, cautions, and recommendations.",Journal of dental education,2024 Sep 1,,https://doi.org/10.1002/jdd.13688
39159585,"['Cai, Jingyi', 'Han, RuiYing', 'Li, Junfu', 'Hao, Jin', 'Zhao, Zhihe', 'Jing, Dian']",Exploring mechanobiology network of bone and dental tissue based on Natural Language Processing.,Journal of biomechanics,2024 Sep,"Bone and cartilage tissues are physiologically dynamic organs that are systematically regulated by mechanical inputs. At cellular level, mechanical stimulation engages an intricate network where mechano-sensors and transmitters cooperate to manipulate downstream signaling. Despite accumulating evidence, there is a notable underutilization of available information, due to limited integration and analysis. In this context, we conceived an interactive web tool named MechanoBone to introduce a new avenue of literature-based discovery. Initially, we compiled a literature database by sourcing content from Pubmed and processing it through the Natural Language Toolkit project, Pubtator, and a custom library. We identified direct co-occurrence among entities based on existing evidence, archiving in a relational database via SQLite. Latent connections were then quantified by leveraging the Link Prediction algorithm. Secondly, mechanobiological pathway maps were generated, and an entity-pathway correlation scoring system was established through weighted algorithm based on our database, String, and KEGG, predicting potential functions of specific entities. Additionally, we established a mechanical circumstance-based exploration to sort genes by their relevance based on big data, revealing the potential mechanically sensitive factors in bone research and future clinical applications. In conclusion, MechanoBone enables: 1) interpreting mechanobiological processes; 2) identifying correlations and crosstalk among molecules and pathways under specific mechanical conditions; 3) connecting clinical applications with mechanobiological processes in bone research. It offers a literature mining tool with visualization and interactivity, facilitating targeted molecule navigation and prediction within the mechanobiological framework of bone-related cells, thereby enhancing knowledge sharing and big data analysis in the biomedical realm.",https://doi.org/10.1016/j.jbiomech.2024.112271
39159544,"['Chen, Haiwen', 'Qu, Zhiyuan', 'Tian, Yuan', 'Jiang, Ning', 'Qin, Yuan', 'Gao, Jie', 'Zhang, Ruoyan', 'Ma, Yanning', 'Jin, Zuolin', 'Zhai, Guangtao']",A cross-temporal multimodal fusion system based on deep learning for orthodontic monitoring.,Computers in biology and medicine,2024 Sep,"INTRODUCTION: In the treatment of malocclusion, continuous monitoring of the three-dimensional relationship between dental roots and the surrounding alveolar bone is essential for preventing complications from orthodontic procedures. Cone-beam computed tomography (CBCT) provides detailed root and bone data, but its high radiation dose limits its frequent use, consequently necessitating an alternative for ongoing monitoring. OBJECTIVES: We aimed to develop a deep learning-based cross-temporal multimodal image fusion system for acquiring root and jawbone information without additional radiation, enhancing the ability of orthodontists to monitor risk. METHODS: Utilizing CBCT and intraoral scans (IOSs) as cross-temporal modalities, we integrated deep learning with multimodal fusion technologies to develop a system that includes a CBCT segmentation model for teeth and jawbones. This model incorporates a dynamic kernel prior model, resolution restoration, and an IOS segmentation network optimized for dense point clouds. Additionally, a coarse-to-fine registration module was developed. This system facilitates the integration of IOS and CBCT images across varying spatial and temporal dimensions, enabling the comprehensive reconstruction of root and jawbone information throughout the orthodontic treatment process. RESULTS: The experimental results demonstrate that our system not only maintains the original high resolution but also delivers outstanding segmentation performance on external testing datasets for CBCT and IOSs. CBCT achieved Dice coefficients of 94.1 % and 94.4 % for teeth and jawbones, respectively, and it achieved a Dice coefficient of 91.7 % for the IOSs. Additionally, in the context of real-world registration processes, the system achieved an average distance error (ADE) of 0.43 mm for teeth and 0.52 mm for jawbones, significantly reducing the processing time. CONCLUSION: We developed the first deep learning-based cross-temporal multimodal fusion system, addressing the critical challenge of continuous risk monitoring in orthodontic treatments without additional radiation exposure. We hope that this study will catalyze transformative advancements in risk management strategies and treatment modalities, fundamentally reshaping the landscape of future orthodontic practice.",https://doi.org/10.1016/j.compbiomed.2024.109025
39139516,"['Jaiswal, Manojkumar', 'Mukhtar, Umer', 'Shakya, Kaushlesh Singh', 'Laddi, Amit', 'Singha, L Akash']",Computerised assessment-a novel approach for calculation of percentage of hypomineralized lesion on incisors and its correlation with aesthetic concern.,Journal of oral biology and craniofacial research,2024 Sep-Oct,"INTRODUCTION: Molar-incisor hypomineralization (MIH) is a localized, qualitative, demarcated enamel defect that affects first permanent molars (FPMs) and/or permanent incisors. The aim of present study was to introduce a novel computerised assessment process to detect and quantify the percentage opacity associated with MIH affected maxillary central incisors. METHODOLOGY: Children (8-16 years) enrolled in the primary study having mild (white/cream or yellow/brown) MIH lesion on fully erupted maxillary permanent central incisor. 50 standardised images of MIH lesions were captured in an artificially lit room with fixed parameters and were anonymized and securely stored. Images were analysed by AI-driven computerised software and generates output classifications via a sophisticated algorithm crafted using a meticulously annotated image dataset as reference through supervised machine learning (SML). For the validation of computerised assessment of MIH lesions, the percentage of demarked opacity was calculated using ADOBE PHOTOSHOP CS7. RESULTS: The percentage of MIH lesion was calculated through histogram plotting with the maxima ranging from 7.29 % to 71.21 % with the mean value of 34.51 %. The validation score ranged from 10.29 % to 67.27 % with the mean value of 35.32 %. The difference between the two was statistically not significant. Out of 50 patients; 11 patients had 1-30 % of surface affected with MIH and 2 had aesthetic concern; 24 had 30-60 % of surface affected and 13 had aesthetic concern; 15 had >60 % of surface affected and 12 had aesthetic concerns. CONCLUSIONS: The proposed approach exhibit sufficient quality to be integrated into a dental software addressing practical challenges encountered in daily clinical settings.",https://doi.org/10.1016/j.jobcr.2024.07.004
39096608,"['Kadi, Hocine', 'Kawczynski, Marzena', 'Bendjama, Sara', 'Flores, Jesus Zegarra', 'Leong-Hoi, Audrey', 'de Lastic, Hugues', 'Balbierer, Julien', 'Mabileau, Claire', 'Radoux, Jean Pierre', 'Grollemund, Bruno', 'Jaegle, Jean', 'Guebert, Christophe', 'Bisch, Bertrand', 'Bloch-Zupan, Agnès']",i-Dent: A virtual assistant to diagnose rare genetic dental diseases.,Computers in biology and medicine,2024 Sep,"Rare genetic diseases are difficult to diagnose and this translates in patient's diagnostic odyssey! This is particularly true for more than 900 rare diseases including orodental developmental anomalies such as missing teeth. However, if left untreated, their symptoms can become significant and disabling for the patient. Early detection and rapid management are therefore essential in this context. The i-Dent project aims to supply a pre-diagnostic tool to detect rare diseases with tooth agenesis of varying severity and pattern. To identify missing teeth, image segmentation models (Mask R-CNN, U-Net) have been trained for the automatic detection of teeth on patients' panoramic dental X-rays. Teeth segmentation enables the identification of teeth which are present or missing within the mouth. Furthermore, a dental age assessment is conducted to verify whether the absence of teeth is an anomaly or a characteristic of the patient's age. Due to the small size of our dataset, we developed a new dental age assessment technique based on the tooth eruption rate. Information about missing teeth is then used by a final algorithm based on the agenesis probabilities to propose a pre-diagnosis of a rare disease. The results obtained in detecting three types of genes (PAX9, WNT10A and EDA) by our system are very promising, providing a pre-diagnosis with an average accuracy of 72 %.",https://doi.org/10.1016/j.compbiomed.2024.108927
39050525,"['Mengi, Arvind', 'Singh, Ravnitya Pal', 'Mengi, Nancy', 'Kalgotra, Sneh', 'Singh, Abhishek']","A questionnaire study regarding knowledge, attitude and usage of artificial intelligence and machine learning by the orthodontic fraternity of Northern India.",Journal of oral biology and craniofacial research,2024 Sep-Oct,"AIM: The aim of the questionnaire study was to determine the knowledge, attitude, and perception of orthodontists regarding the role of artificial intelligence in dentistry in general and orthodontics specifically, and to determine the use of artificial intelligence by the orthodontist. METHODS: This cross-sectional study was done among the orthodontists of Northern India (clinicians, academicians, and postgraduates) through a web-based electronic survey using Google Forms. The study was designed to obtain information about AI and its basic usage in daily life, in dentistry, and in orthodontics from the participants. The options given were set specifically according to the Likert scale to maintain the correct format. The questionnaire was validated by one AI expert and one orthodontic expert, followed by pretesting in a smaller group of 25 orthodontists 2 weeks before circulation. A total of 100 orthodontists and postgraduate students responded to the pretested online questionnaire link for 31 questions in four sections sent via social media websites in a period of 3 months. RESULTS: The majority of the participants believe that AI could be useful in diagnosis and treatment planning and could revolutionize dentistry in general. 84 % of the orthodontic academicians and clinicians, including PG students, consider AI a useful tool for boosting performance and delivering quality care in orthodontics, and 72 % see AI as a partner rather than a competitor in the foreseeable future of dentistry. 90 % of the participants believe that the incorporation of AI into CBCT analysis can be a valuable addition to diagnosis and treatment planning. 86 % of total participants agree that AI can be helpful in decision-making for orthognathic surgery, and 84 % find AI useful for bone age assessment. CONCLUSIONS: It was observed that academicians are more aware of AI terminologies and usage as compared to PG students and clinicians. There is a consensus that AI is a useful tool for diagnosis and treatment planning, boosting performance and quality care in orthodontics. In spite of these facts, 62.5 % of clinicians and 40 % of PG students are still not using AI for cephalometric analysis (p = 0.033).",https://doi.org/10.1016/j.jobcr.2024.06.004
39002299,"['Piyarathne, N S', 'Liyanage, S N', 'Rasnayaka, R M S G K', 'Hettiarachchi, P V K S', 'Devindi, G A I', 'Francis, F B A H', 'Dissanayake, D M D R', 'Ranasinghe, R A N S', 'Pavithya, M B D', 'Nawinne, I B', 'Ragel, R G', 'Jayasinghe, R D']",A comprehensive dataset of annotated oral cavity images for diagnosis of oral cancer and oral potentially malignant disorders.,Oral oncology,2024 Sep,"OBJECTIVES: This study aims to address the critical gap of unavailability of publicly accessible oral cavity image datasets for developing machine learning (ML) and artificial intelligence (AI) technologies for the diagnosis and prognosis of oral cancer (OCA) and oral potentially malignant disorders (OPMD), with a particular focus on the high prevalence and delayed diagnosis in Asia. MATERIALS AND METHODS: Following ethical approval and informed written consent, images of the oral cavity were obtained from mobile phone cameras and clinical data was extracted from hospital records from patients attending to the Dental Teaching Hospital, Peradeniya, Sri Lanka. After data management and hosting, image categorization and annotations were done by clinicians using a custom-made software tool developed by the research team. RESULTS: A dataset comprising 3000 high-quality, anonymized images obtained from 714 patients were classified into four distinct categories: healthy, benign, OPMD, and OCA. Images were annotated with polygonal shaped oral cavity and lesion boundaries. Each image is accompanied by patient metadata, including age, sex, diagnosis, and risk factor profiles such as smoking, alcohol, and betel chewing habits. CONCLUSION: Researchers can utilize the annotated images in the COCO format, along with the patients' metadata, to enhance ML and AI algorithm development.",https://doi.org/10.1016/j.oraloncology.2024.106946
38972447,"['Neumayr, Julia', 'Frenkel, Elisabeth', 'Schwarzmaier, Julia', 'Ammar, Nour', 'Kessler, Andreas', 'Schwendicke, Falk', 'Kühnisch, Jan', 'Dujic, Helena']",External validation of an artificial intelligence-based method for the detection and classification of molar incisor hypomineralisation in dental photographs.,Journal of dentistry,2024 Sep,"OBJECTIVES: This ex vivo diagnostic study aimed to externally validate an open-access artificial intelligence (AI)-based model for the detection, classification, localisation and segmentation of enamel/molar incisor hypomineralisation (EH/MIH). METHODS: An independent sample of web images showing teeth with (n = 277) and without (n = 178) EH/MIH was evaluated by a workgroup of dentists whose consensus served as the reference standard. Then, an AI-based model was used for the detection of EH/MIH, followed by automated classification and segmentation of the findings (test method). The accuracy (ACC), sensitivity (SE), specificity (SP) and area under the curve (AUC) were determined. Furthermore, the correctness of EH/MIH lesion localisation and segmentation was evaluated. RESULTS: An overall ACC of 94.3 % was achieved for image-based detection of EH/MIH. Cross-classification of the AI-based class prediction and the reference standard resulted in an agreement of 89.2 % for all diagnostic decisions (n = 594), with an ACC between 91.4 % and 97.8 %. The corresponding SE and SP values ranged from 81.7 % to 92.8 % and 91.9 % to 98.7 %, respectively. The AUC varied between 0.894 and 0.945. Image size had only a limited impact on diagnostic performance. The AI-based model correctly predicted EH/MIH localisation in 97.3 % of cases. For the detected lesions, segmentation was fully correct in 63.4 % of all cases and partially correct in 33.9 %. CONCLUSIONS: This study documented the promising diagnostic performance of an open-access AI tool in the detection and classification of EH/MIH in external images. CLINICAL SIGNIFICANCE: Externally validated AI-based diagnostic methods could facilitate the detection of EH/MIH lesions in dental photographs.",https://doi.org/10.1016/j.jdent.2024.105228
38904564,"['Yacout, Yomna M', 'Eid, Farah Y', 'Tageldin, Mostafa A', 'Kassem, Hassan E']",Evaluation of the accuracy of automated tooth segmentation of intraoral scans using artificial intelligence-based software packages.,"American journal of orthodontics and dentofacial orthopedics : official publication of the American Association of Orthodontists, its constituent societies, and the American Board of Orthodontics",2024 Sep,"INTRODUCTION: The accuracy of tooth segmentation in intraoral scans is crucial for performing virtual setups and appliance fabrication. Hence, the objective of this study was to estimate and compare the accuracy of automated tooth segmentation generated by the artificial intelligence of dentOne software (DIORCO Co, Ltd, Yongin, South Korea) and Medit Ortho Simulation software (Medit Corp, Seoul, South Korea). METHODS: Twelve maxillary and mandibular pretreatment dental scan sets comprising 286 teeth were collected for this investigation from the archives of the Department of Orthodontics, Faculty of Dentistry, Alexandria University. The scans were imported as standard tessellation language files into both dentOne and Medit Ortho Simulation software. Automatic segmentation was run on each software. The number of successfully segmented teeth vs failed segmentations was recorded to determine the success rate of automated segmentation of each program. Evaluation of success and/or failure was based on the software's identification of the teeth and the quality of the segmentation. The mesiodistal tooth width measurements after segmentation using both tested software programs were compared with those measured on the unsegmented scan using Meshmixer software (Autodesk, San Rafael, Calif). The unsegmented scans served as the reference standard. RESULTS: A total of 288 teeth were examined. Successful identification rates were 99% and 98.3% for Medit and dentOne, respectively. Success rates of segmenting the lingual surfaces of incisors were significantly higher in Medit than in dentOne (93.7% vs 66.7%, respectively; P <0.001). DentOne overestimated the mesiodistal width of canines (0.11 mm, P = 0.032), premolars (0.22 mm, P < 0.001), and molars (0.14 mm, P = 0.043) compared with the reference standard, whereas Medit overestimated the mesiodistal width of premolars only (0.13 mm, P = 0.006). Bland-Altman plots showed that mesiodistal tooth width agreement limits exceeded 0.2 mm between each software and the reference standard. CONCLUSIONS: Both artificial intelligence-segmentation software demonstrated acceptable accuracy in tooth segmentation. There is a need for improvement in segmenting incisor lingual tooth surfaces in dentOne. Both software programs tended to overestimate the mesiodistal widths of segmented teeth, particularly the premolars. Artificial intelligence-segmentation needs to be manually adjusted by the operator to ensure accuracy. However, this still does not solve the problem of proximal surface reconstruction by the software.",https://doi.org/10.1016/j.ajodo.2024.05.015
38896164,"['Nathan, John M', 'Arce, Kevin', 'Herasevich, Vitaly']",The use of artificial intelligence to detect voided medication orders in oral and maxillofacial surgery inpatients.,Oral and maxillofacial surgery,2024 Sep,"OBJECTIVE: The aim of this study is to determine if supervised machine learning algorithms can accurately predict voided computerized physician order entry in oral and maxillofacial surgery inpatients. METHODS: Data from Electronic Medical Record included patient demographics, comorbidities, procedures, vital signs, laboratory values, and medication orders were retrospectively collected. Predictor variables included patient demographics, comorbidities, procedures, vital signs, and laboratory values. Outcome of interest is if a medication order was voided or not. Data was cleaned and processed using Microsoft Excel and Python v3.12. Gradient Boosted Decision Trees, Random Forest, K-Nearest Neighbor, and Naïve Bayes were trained, validated, and tested for accuracy of the prediction of voided medication orders. RESULTS: 37,493 medication orders from 1,204 patient admissions over 5 years were used for this study. 3,892 (10.4%) medication orders were voided. Gradient Boosted Decision Trees, Random Forest, K-Nearest Neighbor, and Naïve Bayes had an Area Under the Receiver Operating Curve of 0.802 with 95% CI [0.787, 0.825], 0.746 with 95% CI [0.722, 0.765], 0.685 with 95% CI [0.667, 0.699], and 0.505 with 95% CI [0.489, 0.539], respectively. Area Under the Precision Recall Curve was 0.684 with 95% CI [0.679, 0.702], 0.647 with 95% CI [0.638, 0.664], 0.429 with 95% CI [0.417, 0.434], and 0.551 with 95% CI [0.551, 0.552], respectively. CONCLUSION: Gradient Boosted Decision Trees was the best performing model of the supervised machine learning algorithms with satisfactory outcomes in the test cohort for predicting voided Computerized Physician Order Entry in Oral and Maxillofacial Surgery inpatients.",https://doi.org/10.1007/s10006-024-01267-6
38857691,"['Fang, Xinle', 'Zhang, Shengben', 'Wei, Zhiyuan', 'Wang, Kaixin', 'Yang, Guanghui', 'Li, Chengliang', 'Han, Min', 'Du, Mi']",Automatic detection of the third molar and mandibular canal on panoramic radiographs based on deep learning.,"Journal of stomatology, oral and maxillofacial surgery",2024 Sep,"PURPOSE: This study aims to develop a deep learning framework for the automatic detection of the position relationship between the mandibular third molar (M3) and the mandibular canal (MC) on panoramic radiographs (PRs), to assist doctors in assessing and planning appropriate surgical interventions. METHODS: Datasets D1 and D2 were obtained by collecting 253 PRs from a hospitals and 197 PRs from online platforms. The RPIFormer model proposed in this study was trained and validated on D1 to create a segmentation model. The CycleGAN model was trained and validated on both D1 and D2 to develop an image enhancement model. Ultimately, the segmentation and enhancement models were integrated with an object detection model to create a fully automated framework for M3 and MC detection in PRs. Experimental evaluation included calculating Dice coefficient, IoU, Recall, and Precision during the process. RESULTS: The RPIFormer model proposed in this study achieved an average Dice coefficient of 92.56 % for segmenting M3 and MC, representing a 3.06 % improvement over the previous best study. The deep learning framework developed in this research enables automatic detection of M3 and MC in PRs without manual cropping, demonstrating superior detection accuracy and generalization capability. CONCLUSION: The framework developed in this study can be applied to PRs captured in different hospitals without the need for model fine-tuning. This feature is significant for aiding doctors in accurately assessing the spatial relationship between M3 and MC, thereby determining the optimal treatment plan to ensure patients' oral health and surgical safety.",https://doi.org/10.1016/j.jormas.2024.101946
38848947,"['Ji, Yinfei', 'Chen, Yunkai', 'Liu, Guanghui', 'Long, Ziteng', 'Gao, Yuxuan', 'Huang, Dingming', 'Zhang, Lan']",Construction and Evaluation of an AI-based CBCT Resolution Optimization Technique for Extracted Teeth.,Journal of endodontics,2024 Sep,"INTRODUCTION: In dental clinical practice, cone-beam computed tomography (CBCT) is commonly used to assist practitioners to recognize the complex morphology of root canal systems; however, because of its resolution limitations, certain small anatomical structures still cannot be accurately recognized on CBCT. The purpose of this study was to perform image super-resolution (SR) processing on CBCT images of extracted human teeth with the help of a deep learning model, and to compare the differences among CBCT, super-resolution computed tomography (SRCT), and micro-computed tomography (Micro-CT) images through three-dimensional reconstruction. METHODS: The deep learning model (Basicvsr++) was selected and modified. The dataset consisted of 171 extracted teeth that met inclusion criteria, with 40 maxillary first molars as the training set and 40 maxillary first molars as well as 91 teeth from other tooth positions as the external test set. The corresponding CBCT, SRCT, and Micro-CT images of each tooth in test sets were reconstructed using Mimics Research 17.0, and the root canal recognition rates in the 3 groups were recorded. The following parameters were measured: volume of hard tissue (V1), volume of pulp chamber and root canal system (V2), length of visible root canals under orifice (VL-X, where X represents the specific root canal), and intersection angle between coronal axis of canal and long axis of tooth (∠X, where X represents the specific root canal). Data were statistically analyzed between CBCT and SRCT images using paired sample t-test and Wilcoxon test analysis, with the measurement from Micro-CT images as the gold standard. RESULTS: Images from all tested teeth were successfully processed with the SR program. In 4-canal maxillary first molar, identification of MB2 was 72% (18/25) in CBCT group, 92% (23/25) in SRCT group, and 100% (25/25) in Micro-CT group. The difference of hard tissue volume between SRCT and Micro-CT was significantly smaller than that between CBCT and Micro-CT in all tested teeth except 4-canal mandibular first molar (P < .05). Similar results were obtained in volume of pulp chamber and root canal system in all tested teeth (P < .05). As for length of visible root canals under orifice, the difference between SRCT and Micro-CT was significantly smaller than that between CBCT and Micro-CT (P < .05) in most root canals. CONCLUSIONS: The deep learning model developed in this study helps to optimize the root canal morphology of extracted teeth in CBCT. And it may be helpful for the identification of MB2 in the maxillary first molar.",https://doi.org/10.1016/j.joen.2024.05.015
38848473,"['Jeong, Hui', 'Han, Sang-Sun', 'Yu, Youngjae', 'Kim, Saejin', 'Jeon, Kug Jin']",How well do large language model-based chatbots perform in oral and maxillofacial radiology?,Dento maxillo facial radiology,2024 Sep 1,"OBJECTIVES: This study evaluated the performance of four large language model (LLM)-based chatbots by comparing their test results with those of dental students on an oral and maxillofacial radiology examination. METHODS: ChatGPT, ChatGPT Plus, Bard, and Bing Chat were tested on 52 questions from regular dental college examinations. These questions were categorized into three educational content areas: basic knowledge, imaging and equipment, and image interpretation. They were also classified as multiple-choice questions (MCQs) and short-answer questions (SAQs). The accuracy rates of the chatbots were compared with the performance of students, and further analysis was conducted based on the educational content and question type. RESULTS: The students' overall accuracy rate was 81.2%, while that of the chatbots varied: 50.0% for ChatGPT, 65.4% for ChatGPT Plus, 50.0% for Bard, and 63.5% for Bing Chat. ChatGPT Plus achieved a higher accuracy rate for basic knowledge than the students (93.8% vs. 78.7%). However, all chatbots performed poorly in image interpretation, with accuracy rates below 35.0%. All chatbots scored less than 60.0% on MCQs, but performed better on SAQs. CONCLUSIONS: The performance of chatbots in oral and maxillofacial radiology was unsatisfactory. Further training using specific, relevant data derived solely from reliable sources is required. Additionally, the validity of these chatbots' responses must be meticulously verified.",https://doi.org/10.1093/dmfr/twae021
38821263,"['Wu, Weiwei', 'Chen, Surong', 'Chen, Pan', 'Chen, Min', 'Yang, Yan', 'Gao, Yuan', 'Hu, Jingyu', 'Ma, Jingzhi']",Identification of Root Canal Morphology in Fused-rooted Mandibular Second Molars From X-ray Images Based on Deep Learning.,Journal of endodontics,2024 Sep,"INTRODUCTION: Understanding the intricate anatomical morphology of fused-rooted mandibular second molars (MSMs) is essential for root canal treatment. The present study utilized a deep learning approach to identify the three-dimensional root canal morphology of MSMs from two-dimensional X-ray images. METHODS: A total of 271 fused-rooted MSMs were included in the study. Micro-computed tomography reconstruction images and two-dimensional X-ray projection images were obtained. The ground truth of three-dimensional root canal morphology was determined through micro-computed tomography images, which were classified into merging, symmetrical, and asymmetrical types. To amplify the X-ray image dataset, traditional augmentation techniques from the python package Augmentor and a multiangle projection method were employed. Identification of root canal morphology was conducted using the pretrained VGG19, ResNet18, ResNet50, and EfficientNet-b5 on X-ray images. The classification results from convolutional neural networks (CNNs) were then compared with those performed by endodontic residents. RESULTS: The multiangle projection augmentation method outperformed the traditional approach in all CNNs except for EfficientNet-b5. ResNet18 combined with the multiangle projection method outperformed all other combinations, with an overall accuracy of 79.25%. In specific classifications, accuracies of 81.13%, 86.79%, and 90.57% were achieved for merging, symmetrical, and asymmetrical types, respectively. Notably, CNNs surpassed endodontic residents in classification performance; the average accuracy for endodontic residents was only 60.38% (P < .05). CONCLUSIONS: CNNs were more effective than endodontic residents in identifying the three-dimensional root canal morphology of MSMs. The result indicates that CNNs possess the capacity to employ two-dimensional images effectively in aiding three-dimensional diagnoses.",https://doi.org/10.1016/j.joen.2024.05.014
38735467,"['Büttner, Martha', 'Schneider, Lisa', 'Krasowski, Aleksander', 'Pitchika, Vinay', 'Krois, Joachim', 'Meyer-Lueckel, Hendrik', 'Schwendicke, Falk']",Conquering class imbalances in deep learning-based segmentation of dental radiographs with different loss functions.,Journal of dentistry,2024 Sep,"OBJECTIVE: The imbalanced nature of real-world datasets is an ongoing challenge in the field of machine and deep learning. In medicine and in dentistry, most data samples represent patients not affected by pathologies, and on imagery, pathologic image areas are often smaller than healthy ones. Selecting suitable loss functions during deep learning is essential and may help to overcome the resulting imbalance. We assessed six different loss functions for one exemplary task, tooth structure segmentation on bitewing radiographs, for their performance. METHODS: Six different loss functions (Focal Loss, Dice Loss, Tversky Loss and hybrid losses of Cross-Entropy and Dice Loss, Focal and Dice Loss, Focal and Generalized Dice Loss) were compared on a tooth structure segmentation task of 1,625 bitewing radiographs. Training was performed using three different model architectures (U-Net, Linknet, DeepLavbV3+) over a 5-fold cross-validation. Tooth structures consisted of the classes (occurrence in% of samples/captures areas measured on pixel level) enamel (100 %/25 %), dentin (100 %/50 %), root canal (100 %/10 %), filling (81 %/8 %) and crown (28 %/5 %). RESULTS: Hybrid loss functions significantly outperformed standalone ones and provided robust results over the different architectures for the classes enamel, dentin, root canal and filling. Specifically, the Dice Focal loss reached high performance to conquer both image level and pixel level class imbalance, respectively. CLINICAL SIGNIFICANCE: In dental use cases it is often important to predict minority classes such as pathologies accurately. Using specific loss function may be an effective strategy to overcome data imbalance when training deep learning models.",https://doi.org/10.1016/j.jdent.2024.105063
38706403,"[""O'Rourke, Samuel P"", 'Stack, Taylor J', 'Miller, Jonas R', 'Miller, Matthew Q']",Changes in Perceived Emotions in Facial Paralysis Patients After Depressor Anguli Oris Excision.,The Laryngoscope,2024 Sep,"OBJECTIVES: Depressor anguli oris (DAO) excision can improve clinician-graded, objective, and patient-reported smile outcomes in patients with nonflaccid facial paralysis (NFFP). However, no prior research has studied changes in perceived emotions after surgery. This study quantifies changes in perceived emotions with smiling after DAO excision in the largest case series presented to date. METHODS: Prospectively collected data from patients with NFFP who underwent DAO excision at a tertiary care facial nerve center were reviewed. Patient-reported, clinician-graded, and objective smile metrics were compared before and after surgery. Videos of faces at rest and while smiling were analyzed by artificial intelligence-derived facial expression analysis software to quantify perceived emotions. RESULTS: Sixty-eight patients underwent isolated DAO excision between August 2021 and August 2023. Patients conveyed significantly more perceived happiness with smile and at rest after surgery (p < 0.001 and p = 0.012, respectively). DAO excision improved oral commissure excursion (p < 0.001), dental show (p < 0.001), and smile angle (p < 0.001) symmetry. Patients reported significant improvements in smiling and social function after surgery. CONCLUSIONS: This study demonstrates DAO excision increases perceived happiness conveyed by patients with NFFP while smiling and at rest. It confirms improved objective, clinician-graded, and patient-reported smile outcomes after surgery. LEVEL OF EVIDENCE: 4 Laryngoscope, 134:4028-4035, 2024.",https://doi.org/10.1002/lary.31471
38683703,"['Zhan, Xianghao', 'Liu, Yuzhe', 'Cecchi, Nicholas J', 'Callan, Ashlyn A', 'Le Flao, Enora', 'Gevaert, Olivier', 'Zeineh, Michael M', 'Grant, Gerald A', 'Camarillo, David B']",AI-Based Denoising of Head Impact Kinematics Measurements With Convolutional Neural Network for Traumatic Brain Injury Prediction.,IEEE transactions on bio-medical engineering,2024 Sep,"OBJECTIVE: Wearable devices are developed to measure head impact kinematics but are intrinsically noisy because of the imperfect interface with human bodies. This study aimed to improve the head impact kinematics measurements obtained from instrumented mouthguards using deep learning to enhance traumatic brain injury (TBI) risk monitoring. METHODS: We developed one-dimensional convolutional neural network (1D-CNN) models to denoise mouthguard kinematics measurements for tri-axial linear acceleration and tri-axial angular velocity from 163 laboratory dummy head impacts. The performance of the denoising models was evaluated on three levels: kinematics, brain injury criteria, and tissue-level strain and strain rate. Additionally, we performed a blind test on an on-field dataset of 118 college football impacts and a test on 413 post-mortem human subject (PMHS) impacts. RESULTS: On the dummy head impacts, the denoised kinematics showed better correlation with reference kinematics, with relative reductions of 36% for pointwise root mean squared error and 56% for peak absolute error. Absolute errors in six brain injury criteria were reduced by a mean of 82%. For maximum principal strain and maximum principal strain rate, the mean error reduction was 35% and 69%, respectively. On the PMHS impacts, similar denoising effects were observed and the peak kinematics after denoising were more accurate (relative error reduction for 10% noisiest impacts was 75.6%). CONCLUSION: The 1D-CNN denoising models effectively reduced errors in mouthguard-derived kinematics measurements on dummy and PMHS impacts. SIGNIFICANCE: This study provides a novel approach for denoising head kinematics measurements in dummy and PMHS impacts, which can be further validated on more real-human kinematics data before real-world applications.",https://doi.org/10.1109/TBME.2024.3392537
38652576,"['Yari, Amir', 'Fasih, Paniz', 'Hosseini Hooshiar, Mohammad', 'Goodarzi, Ali', 'Fattahi, Seyedeh Farnaz']",Detection and classification of mandibular fractures in panoramic radiography using artificial intelligence.,Dento maxillo facial radiology,2024 Sep 1,"OBJECTIVES: This study evaluated the performance of the YOLOv5 deep learning model in detecting different mandibular fracture types in panoramic images. METHODS: The dataset of panoramic radiographs with mandibular fractures was divided into training, validation, and testing sets, with 60%, 20%, and 20% of the images, respectively. An equal number of control images without fractures were also distributed among the datasets. The YOLOv5 algorithm was trained to detect six mandibular fracture types based on the anatomical location including symphysis, body, angle, ramus, condylar neck, and condylar head. Performance metrics of accuracy, precision, sensitivity (recall), specificity, dice coefficient (F1 score), and area under the curve (AUC) were calculated for each class. RESULTS: A total of 498 panoramic images containing 673 fractures were collected. The accuracy was highest in detecting body (96.21%) and symphysis (95.87%), and was lowest in angle (90.51%) fractures. The highest and lowest precision values were observed in detecting symphysis (95.45%) and condylar head (63.16%) fractures, respectively. The sensitivity was highest in the body (96.67%) fractures and was lowest in the condylar head (80.00%) and condylar neck (81.25%) fractures. The highest specificity was noted in symphysis (98.96%), body (96.08%), and ramus (96.04%) fractures, respectively. The dice coefficient and AUC were highest in detecting body fractures (0.921 and 0.942, respectively), and were lowest in detecting condylar head fractures (0.706 and 0.812, respectively). CONCLUSION: The trained algorithm achieved promising results in detecting most fracture types, particularly in body and symphysis regions indicating machine learning potential as a diagnostic aid for clinicians.",https://doi.org/10.1093/dmfr/twae018
38468123,"['Modesto-Mata, Mario', 'de la Fuente Valentín, Luis', 'Hlusko, Leslea J', 'Martínez de Pinillos, Marina', 'Towle, Ian', 'García-Campos, Cecilia', 'Martinón-Torres, María', 'Bermúdez de Castro, José María']",Artificial neural networks reconstruct missing perikymata in worn teeth.,"Anatomical record (Hoboken, N.J. : 2007)",2024 Sep,"Dental evolutionary studies in hominins are key to understanding how our ancestors and close fossil relatives grew from the early stages of embryogenesis into adults. In a sense, teeth are like an airplane's 'black box' as they record important variables for assessing developmental timing, enabling comparisons within and between populations, species, and genera. The ability to discern this type of nuanced information is embedded in the nature of how tooth enamel and dentin form: incrementally and over years. This incremental growth leaves chronological indicators in the histological structure of enamel, visible on the crown surface as perikymata. These structures are used in the process of reconstructing the rate and timing of tooth formation. Unfortunately, the developmentally earliest growth lines in lateral enamel are quickly lost to wear once the tooth crown erupts. We developed a method to reconstruct these earliest, missing perilymata from worn teeth through knowledge of the later-developed, visible perikymata for all tooth types (incisors, canines, premolars, and molars) using a modern human dataset. Building on our previous research using polynomial regressions, here we describe an artificial neural networks (ANN) method. This new ANN method mostly predicts within 2 counts the number of perikymata present in each of the first three deciles of the crown height for all tooth types. Our ANN method for estimating perikymata lost through wear has two immediate benefits: more accurate values can be produced and worn teeth can be included in dental research. This tool is available on the open-source platform R within the package teethR released under GPL v3.0 license, enabling other researchers the opportunity to expand their datasets for studies of periodicity in histological growth, dental development, and evolution.",https://doi.org/10.1002/ar.25416
38462066,"['Leblebicioglu Kurtulus, Ikbal', 'Lubbad, Mohammed', 'Yilmaz, Ozden Melis Durmaz', 'Kilic, Kerem', 'Karaboga, Dervis', 'Basturk, Alper', 'Akay, Bahriye', 'Nalbantoglu, Ufuk', 'Yilmaz, Serkan', 'Ayata, Mustafa', 'Pacal, Ishak']",A robust deep learning model for the classification of dental implant brands.,"Journal of stomatology, oral and maxillofacial surgery",2024 Sep,"OBJECTIVE: In cases where the brands of implants are not known, treatment options can be significantly limited in potential complications arising from implant procedures. This research aims to explore the application of deep learning techniques for the classification of dental implant systems using panoramic radiographs. The primary objective is to assess the superiority of the proposed model in achieving accurate and efficient dental implant classification. MATERIAL AND METHODS: A comprehensive analysis was conducted using a diverse set of 25 convolutional neural network (CNN) models, including popular architectures such as VGG16, ResNet-50, EfficientNet, and ConvNeXt. The dataset of 1258 panoramic radiographs from patients who underwent implant treatment at faculty of dentistry was utilized for training and evaluation. Six different dental implant systems were employed as prototypes for the classification task. The precision, recall, F1 score, and support scores for each class have included in the classification accuracy report to ensure accurate and reliable results from the model. RESULTS: The experimental results demonstrate that the proposed model consistently outperformed the other evaluated CNN architectures in terms of accuracy, precision, recall, and F1-score. With an impressive accuracy of 95.74 % and high precision and recall rates, the ConvNeXt model showcased its superiority in accurately classifying dental implant systems. Notably, the model's performance was achieved with a relatively smaller number of parameters, indicating its efficiency and speed during inference. CONCLUSION: The findings highlight the effectiveness of deep learning techniques, particularly the proposed model, in accurately classifying dental implant systems from panoramic radiographs.",https://doi.org/10.1016/j.jormas.2024.101818
38460321,"['Franco, A', 'Cornacchia, A P', 'Moreira, D', 'Miamoto, P', 'Bueno, J', 'Murray, J', 'Heng, D', 'Mânica, S', 'Porto, L', 'Abade, A']",Radiographic morphology of canines tested for sexual dimorphism via convolutional-neural-network-based artificial intelligence.,Morphologie : bulletin de l'Association des anatomistes,2024 Sep,"The permanent left mandibular canines have been used for sexual dimorphism when human identification is necessary. Controversy remains whether the morphology of these teeth is actually useful to distinguish males and females. This study aimed to assess the sexual dimorphism of canines by means of a pioneering artificial intelligence approach to this end. A sample of 13,046 teeth radiographically registered from 5838 males and 7208 females between the ages of 6 and 22.99 years was collected. The images were annotated using Darwin V7 software. DenseNet121 was used and tested based on binary answers regarding the sex (male or female) of the individuals for 17 age categories of one year each (i.e. 6-6.99, 7.7.99… 22.22.99). Accuracy rates, receiver operating characteristic (ROC) curves and confusion matrices were used to quantify and express the artificial intelligence's classification performance. The accuracy rates across age categories were between 57-76% (mean: 68%±5%). The area under the curve (AUC) of the ROC analysis was between 0.58 and 0.77. The best performances were observed around the age of 12 years, while the worst were around the age of 7 years. The morphological analysis of canines for sex estimation should be restricted and allowed in practice only when other sources of dimorphic anatomic features are not available.",https://doi.org/10.1016/j.morpho.2024.100772
38458545,"['Torul, Damla', 'Akpinar, Hasan', 'Bayrakdar, Ibrahim Sevki', 'Celik, Ozer', 'Orhan, Kaan']",Prediction of extraction difficulty for impacted maxillary third molars with deep learning approach.,"Journal of stomatology, oral and maxillofacial surgery",2024 Sep,"OBJECTIVE: The aim of this study is to determine if a deep learning (DL) model can predict the surgical difficulty for impacted maxillary third molar tooth using panoramic images before surgery. MATERIALS AND METHODS: The dataset consists of 708 panoramic radiographs of the patients who applied to the Oral and Maxillofacial Surgery Clinic for various reasons. Each maxillary third molar difficulty was scored based on dept (V), angulation (H), relation with maxillary sinus (S), and relation with ramus (R) on panoramic images. The YoloV5x architecture was used to perform automatic segmentation and classification. To prevent re-testing of images, participate in the training, the data set was subdivided as: 80 % training, 10 % validation, and 10 % test group. RESULTS: Impacted Upper Third Molar Segmentation model showed best success on sensitivity, precision and F1 score with 0,9705, 0,9428 and 0,9565, respectively. S-model had a lesser sensitivity, precision and F1 score than the other models with 0,8974, 0,6194, 0,7329, respectively. CONCLUSION: The results showed that the proposed DL model could be effective for predicting the surgical difficulty of an impacted maxillary third molar tooth using panoramic radiographs and this approach might help as a decision support mechanism for the clinicians in peri‑surgical period.",https://doi.org/10.1016/j.jormas.2024.101817
